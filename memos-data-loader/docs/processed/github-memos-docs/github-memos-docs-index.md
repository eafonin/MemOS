{"file": "dashboard-api-error_code.md", "path": "docs/processed/github-memos-docs/dashboard-api-error_code.md", "description": "API reference for | Code | Meaning | Resolution | | --- | --- | --- | | 0 | Success | | | 50000 | System error | Please try again later | | 40000 | Parameter error | Modify the request parameters |.", "priority": 2, "bytes": 207, "type": "api-reference"}
{"file": "dashboard-api-overview.md", "path": "docs/processed/github-memos-docs/dashboard-api-overview.md", "description": "Overview of MemOS currently provides two types of APIs to help developers store and retrieve conversation memory:.", "priority": 2, "bytes": 2541, "type": "api-reference"}
{"file": "dashboard-limit.md", "path": "docs/processed/github-memos-docs/dashboard-limit.md", "description": "The MemOS Cloud Service currently provides all developers with the following free development quotas for the APIs, calculated based on number of calls. Different APIs consume quota differently, as shown in the table below:.", "priority": 2, "bytes": 2745, "type": "documentation"}
{"file": "dashboard-overview.md", "path": "docs/processed/github-memos-docs/dashboard-overview.md", "description": "Overview of - Memory-focused Optimization: MemOS focuses on managing and optimizing long-term and short-term memory, supporting context retention, user personalization, and cross-session tracking, helping your application truly gain \"memory capabi...", "priority": 2, "bytes": 1307, "type": "overview"}
{"file": "dashboard-quick_start.md", "path": "docs/processed/github-memos-docs/dashboard-quick_start.md", "description": "Guide for Register and log in to the MemOS Cloud Platform. A default project will be created for you automatically. Copy the default API Key from the console.", "priority": 2, "bytes": 11526, "type": "guide"}
{"file": "open_source-best_practice-common_errors_solutions.md", "path": "docs/processed/github-memos-docs/open_source-best_practice-common_errors_solutions.md", "description": "python ‚úÖ Always include required fields llmconfig = { \"backend\": \"openai\", \"config\": { \"apikey\": \"your-api-key\", \"modelnameorpath\": \"gpt-4\" } } .", "priority": 2, "bytes": 1349, "type": "documentation"}
{"file": "open_source-best_practice-mcp_for_cozespace_and_tools.md", "path": "docs/processed/github-memos-docs/open_source-best_practice-mcp_for_cozespace_and_tools.md", "description": "This guide will help you configure MemOS MCP services and create custom tool plugins in Coze Space, enabling seamless integration between intelligent agents and memory systems.", "priority": 2, "bytes": 3540, "type": "documentation"}
{"file": "open_source-best_practice-memory_structure_design.md", "path": "docs/processed/github-memos-docs/open_source-best_practice-memory_structure_design.md", "description": "Best for: Knowledge management, research assistants, hierarchical data python treeconfig = { \"backend\": \"treetext\", \"config\": { \"extractorllm\": { \"backend\": \"ollama\", \"config\": { \"modelnameorpath\": \"qwen3:0.6b\" } }, \"graphdb\": { \"backend\": \"neo4j\"...", "priority": 2, "bytes": 1922, "type": "documentation"}
{"file": "open_source-best_practice-network_workarounds.md", "path": "docs/processed/github-memos-docs/open_source-best_practice-network_workarounds.md", "description": "To download Huggingface models using the mirror site, you can follow these steps:.", "priority": 2, "bytes": 2908, "type": "documentation"}
{"file": "open_source-best_practice-performance_tuning.md", "path": "docs/processed/github-memos-docs/open_source-best_practice-performance_tuning.md", "description": "python fastembedder = { \"backend\": \"ollama\", \"config\": { \"modelnameorpath\": \"nomic-embed-text:latest\" } }.", "priority": 2, "bytes": 1121, "type": "documentation"}
{"file": "open_source-contribution-commit_guidelines.md", "path": "docs/processed/github-memos-docs/open_source-contribution-commit_guidelines.md", "description": "Guide for Please follow the Conventional Commits format:.", "priority": 2, "bytes": 433, "type": "documentation"}
{"file": "open_source-contribution-development_workflow.md", "path": "docs/processed/github-memos-docs/open_source-contribution-development_workflow.md", "description": "If you've previously forked the repository, sync with the upstream changes:.", "priority": 2, "bytes": 1619, "type": "documentation"}
{"file": "open_source-contribution-overview.md", "path": "docs/processed/github-memos-docs/open_source-contribution-overview.md", "description": "Overview of - First-time contributors: Please start by reading the Setting Up guide to prepare your development environment. - Ready to code. The Development Workflow guide will walk you through our process for submitting changes.", "priority": 2, "bytes": 1058, "type": "overview"}
{"file": "open_source-contribution-setting_up.md", "path": "docs/processed/github-memos-docs/open_source-contribution-setting_up.md", "description": "- Fork the repository on GitHub - Clone your fork to your local machine: bash git clone https://github.com/YOUR-USERNAME/MemOS.git cd MemOS - Add the upstream repository as a remote: bash git remote add upstream https://github.com/MemTensor/MemOS....", "priority": 2, "bytes": 1124, "type": "documentation"}
{"file": "open_source-contribution-writing_docs.md", "path": "docs/processed/github-memos-docs/open_source-contribution-writing_docs.md", "description": "::steps Create Markdown File Create a new .md file in the content/ directory or its subdirectories. Choose an appropriate location based on your content type.", "priority": 2, "bytes": 13200, "type": "documentation"}
{"file": "open_source-contribution-writing_tests.md", "path": "docs/processed/github-memos-docs/open_source-contribution-writing_tests.md", "description": "1. Create a new Python file in the tests/ directory. The filename should start with test.", "priority": 2, "bytes": 1190, "type": "documentation"}
{"file": "open_source-cookbook-chapter1-api.md", "path": "docs/processed/github-memos-docs/open_source-cookbook-chapter1-api.md", "description": "API reference for  Recipe 1.1: Install and Configure Your MemOS Development Environment (API Version).", "priority": 2, "bytes": 39048, "type": "api-reference"}
{"file": "open_source-cookbook-chapter1-ollama.md", "path": "docs/processed/github-memos-docs/open_source-cookbook-chapter1-ollama.md", "description": "Tutorial demonstrating  Recipe 1.1: Install and Configure Your MemOS Development Environment (Ollama Version).", "priority": 2, "bytes": 44900, "type": "tutorial"}
{"file": "open_source-cookbook-chapter2-api.md", "path": "docs/processed/github-memos-docs/open_source-cookbook-chapter2-api.md", "description": "API reference for üéØ Problem Scenario: You are an AI application developer who has learned the basic operations of MemOS and now wants to create a more structured memory system. You find that the basic TextualMemoryMetadata functionality is limited...", "priority": 2, "bytes": 15649, "type": "api-reference"}
{"file": "open_source-cookbook-chapter2-ollama.md", "path": "docs/processed/github-memos-docs/open_source-cookbook-chapter2-ollama.md", "description": "Tutorial demonstrating üéØ Problem Scenario: You are an AI application developer who has learned the basic operations of MemOS and now wants to create a more structured memory system. You find that the basic TextualMemoryMetadata functionality is li...", "priority": 2, "bytes": 17079, "type": "tutorial"}
{"file": "open_source-cookbook-chapter3-overview.md", "path": "docs/processed/github-memos-docs/open_source-cookbook-chapter3-overview.md", "description": "Overview of  üÜö Why Choose MemOS. Traditional Methods vs MemOS Comparison.", "priority": 2, "bytes": 43798, "type": "tutorial"}
{"file": "open_source-cookbook-chapter4-overview.md", "path": "docs/processed/github-memos-docs/open_source-cookbook-chapter4-overview.md", "description": "Overview of When building domain-specific Knowledge Q&A (QA) systems, the industry faces a common challenge: although Large Language Models (LLMs) have broad knowledge, they still lack precision and reliability in specialized domains; while tradit...", "priority": 2, "bytes": 199114, "type": "tutorial"}
{"file": "open_source-cookbook-overview.md", "path": "docs/processed/github-memos-docs/open_source-cookbook-overview.md", "description": "Overview of Welcome to the MemOS Cookbook. This is not a traditional technical documentation, but a hands-on guide focused on solving real problems.", "priority": 2, "bytes": 8718, "type": "tutorial"}
{"file": "open_source-getting_started-examples.md", "path": "docs/processed/github-memos-docs/open_source-getting_started-examples.md", "description": "Tutorial demonstrating :::card --- icon: ri:play-line title: Minimal Pipeline to: /opensource/gettingstarted/examplesexample-1-minimal-pipeline --- The smallest working pipeline ‚Äî add, search, update and dump plaintext memories. :::.", "priority": 2, "bytes": 11925, "type": "tutorial"}
{"file": "open_source-getting_started-installation.md", "path": "docs/processed/github-memos-docs/open_source-getting_started-installation.md", "description": "For detailed development environment setup, workflow guidelines, and contribution best practices, please see our Contribution Guide.", "priority": 2, "bytes": 1804, "type": "guide"}
{"file": "open_source-getting_started-quick_start.md", "path": "docs/processed/github-memos-docs/open_source-getting_started-quick_start.md", "description": "Guide for  What You'll Learn Welcome. This guide will help you install, initialize, and run your first memory-augmented LLM app in just a few minutes.", "priority": 2, "bytes": 2606, "type": "guide"}
{"file": "open_source-getting_started-rest_api_server.md", "path": "docs/processed/github-memos-docs/open_source-getting_started-rest_api_server.md", "description": "API reference for !MemOS Architecture <div style=\"text-align: center; margin-top: 10px\">APIs supported by MemOS REST API Server</div>.", "priority": 2, "bytes": 10566, "type": "api-reference"}
{"file": "open_source-getting_started-your_first_memory.md", "path": "docs/processed/github-memos-docs/open_source-getting_started-your_first_memory.md", "description": "By the end of this guide, you will: - Extract memories from plain text or chat messages. - Store them as semantic vectors. - Search and manage them using vector similarity.", "priority": 2, "bytes": 7700, "type": "guide"}
{"file": "open_source-home-architecture.md", "path": "docs/processed/github-memos-docs/open_source-home-architecture.md", "description": "Architecture documentation of The orchestration layer of MemOS ‚Äî it manages predictive, asynchronous scheduling across multiple memory types (plaintext, activation, parametric) and orchestrates multi-user, multi-session memory workflows.", "priority": 2, "bytes": 3448, "type": "technical"}
{"file": "open_source-home-core_concepts.md", "path": "docs/processed/github-memos-docs/open_source-home-core_concepts.md", "description": "MOS (Memory Operating System) MemCube Memory Types Cross-Cutting Concepts.", "priority": 2, "bytes": 4493, "type": "documentation"}
{"file": "open_source-home-memos_intro.md", "path": "docs/processed/github-memos-docs/open_source-home-memos_intro.md", "description": "As LLMs advance to handle complex tasks ‚Äî like multi-turn dialogue, long-term planning, decision-making, and personalized user experiences ‚Äî their ability to structure, manage, and evolve memory becomes critical for achieving true long-term intell...", "priority": 2, "bytes": 5733, "type": "documentation"}
{"file": "open_source-home-overview.md", "path": "docs/processed/github-memos-docs/open_source-home-overview.md", "description": "Overview of As large language models (LLMs) evolve to tackle advanced tasks‚Äîsuch as multi-turn dialogue, planning, decision-making, and personalized agents‚Äîtheir ability to manage and utilize memory becomes crucial for achieving long-term intellig...", "priority": 2, "bytes": 2654, "type": "overview"}
{"file": "open_source-modules-mem_cube.md", "path": "docs/processed/github-memos-docs/open_source-modules-mem_cube.md", "description": "A MemCube is a container that bundles three major types of memory:.", "priority": 2, "bytes": 3003, "type": "documentation"}
{"file": "open_source-modules-mem_reader.md", "path": "docs/processed/github-memos-docs/open_source-modules-mem_reader.md", "description": "First, configure and initialize the reader with your preferred LLM and embedder models.", "priority": 2, "bytes": 5238, "type": "documentation"}
{"file": "open_source-modules-mem_scheduler.md", "path": "docs/processed/github-memos-docs/open_source-modules-mem_scheduler.md", "description": "- üöÄ Concurrent operation with MemOS system - üß† Multi-memory coordination (Working/Long-Term/User memory) - ‚ö° Event-driven scheduling for memory operations - üîç Efficient retrieval of relevant memory items - üìä Comprehensive monitoring of memory usag...", "priority": 2, "bytes": 6100, "type": "documentation"}
{"file": "open_source-modules-memories-general_textual_memory.md", "path": "docs/processed/github-memos-docs/open_source-modules-memories-general_textual_memory.md", "description": "Each memory is represented as a TextualMemoryItem:.", "priority": 2, "bytes": 4423, "type": "documentation"}
{"file": "open_source-modules-memories-kv_cache_memory.md", "path": "docs/processed/github-memos-docs/open_source-modules-memories-kv_cache_memory.md", "description": "In MemOS, KV-cache memory is best suited for storing semantically stable and frequently reused background content such as:.", "priority": 2, "bytes": 14082, "type": "documentation"}
{"file": "open_source-modules-memories-nebula_graph_db.md", "path": "docs/processed/github-memos-docs/open_source-modules-memories-nebula_graph_db.md", "description": "Designed for large-scale distributed deployment Flexible support for labels and properties on both nodes and edges Built-in vector index support (starting from Nebula 5).", "priority": 2, "bytes": 3769, "type": "documentation"}
{"file": "open_source-modules-memories-neo4j_graph_db.md", "path": "docs/processed/github-memos-docs/open_source-modules-memories-neo4j_graph_db.md", "description": "Unlike flat vector stores, a graph database allows:.", "priority": 2, "bytes": 5036, "type": "documentation"}
{"file": "open_source-modules-memories-parametric_memory.md", "path": "docs/processed/github-memos-docs/open_source-modules-memories-parametric_memory.md", "description": "::note Coming Soon This feature is still under active development. Stay tuned for updates. ::.", "priority": 2, "bytes": 2480, "type": "documentation"}
{"file": "open_source-modules-memories-tree_textual_memory.md", "path": "docs/processed/github-memos-docs/open_source-modules-memories-tree_textual_memory.md", "description": "Let‚Äôs build your first graph-based, tree-structured memory in MemOS!.", "priority": 2, "bytes": 12146, "type": "documentation"}
{"file": "open_source-modules-model_backend.md", "path": "docs/processed/github-memos-docs/open_source-modules-model_backend.md", "description": "Overview <a id=\"overview\"></a> MemOS decouples model logic from runtime config via two Pydantic factories:.", "priority": 2, "bytes": 3606, "type": "documentation"}
{"file": "open_source-modules-mos-memos_mcp.md", "path": "docs/processed/github-memos-docs/open_source-modules-mos-memos_mcp.md", "description": "Create a .env file in your project root with the following configuration:.", "priority": 2, "bytes": 3079, "type": "documentation"}
{"file": "open_source-modules-mos-memos_neo.md", "path": "docs/processed/github-memos-docs/open_source-modules-mos-memos_neo.md", "description": "bash export OPENAIAPIKEY=\"sk-your-api-key-here\" export OPENAIAPIBASE=\"https://api.openai.com/v1\" Optional export MOSTEXTMEMTYPE=\"generaltext\" or \"treetext\" for advanced.", "priority": 2, "bytes": 4597, "type": "documentation"}
{"file": "open_source-modules-mos-overview.md", "path": "docs/processed/github-memos-docs/open_source-modules-mos-overview.md", "description": "Overview of  Initialization python from memos import MOS mos = MOS(config: MOSConfig) .", "priority": 2, "bytes": 11748, "type": "overview"}
{"file": "open_source-modules-mos-users.md", "path": "docs/processed/github-memos-docs/open_source-modules-mos-users.md", "description": "MOS supports four user roles with different permission levels:.", "priority": 2, "bytes": 9310, "type": "documentation"}
{"file": "open_source-modules-mos-users_configurations.md", "path": "docs/processed/github-memos-docs/open_source-modules-mos-users_configurations.md", "description": "1. Configuration Overview 2. MOS Configuration 3.", "priority": 2, "bytes": 19495, "type": "documentation"}
{"file": "overview-algorithm.md", "path": "docs/processed/github-memos-docs/overview-algorithm.md", "description": "Overview of ::note Reference: Paper link https://arxiv.org/abs/2507.03724 ::.", "priority": 2, "bytes": 8053, "type": "overview"}
{"file": "overview-faq.md", "path": "docs/processed/github-memos-docs/overview-faq.md", "description": "Overview of  Q: What is the difference between MemOS and a standard RAG framework?.", "priority": 2, "bytes": 6055, "type": "overview"}
{"file": "overview-introduction.md", "path": "docs/processed/github-memos-docs/overview-introduction.md", "description": "Introduction to Its goal is: to enable your AI system to have long-term memory like a human, not only remembering what users have said but also actively invoking, updating, and scheduling these memories.", "priority": 2, "bytes": 2954, "type": "overview"}
{"file": "overview-quick_start-mem_lifecycle.md", "path": "docs/processed/github-memos-docs/overview-quick_start-mem_lifecycle.md", "description": "Overview of  1. Capability Overview A memory, once generated, may gradually consolidate into a stable long-term preference, or be removed if it becomes outdated or invalid. :::note Tip<br> This evolutionary process is called Memory Lifecycle Manag...", "priority": 2, "bytes": 5407, "type": "guide"}
{"file": "overview-quick_start-mem_production.md", "path": "docs/processed/github-memos-docs/overview-quick_start-mem_production.md", "description": "Overview of  1. Capability Introduction: Why Process Raw Messages into Memory.", "priority": 2, "bytes": 5029, "type": "guide"}
{"file": "overview-quick_start-mem_recall.md", "path": "docs/processed/github-memos-docs/overview-quick_start-mem_recall.md", "description": "Overview of Memory recall is responsible for quickly retrieving the most relevant memory fragments when the user initiates a new request.", "priority": 2, "bytes": 13024, "type": "guide"}
{"file": "overview-quick_start-mem_schedule.md", "path": "docs/processed/github-memos-docs/overview-quick_start-mem_schedule.md", "description": "Overview of In MemOS, Memory Scheduling improves efficiency and accuracy by dynamically coordinating memories of different usage efficiencies (Parameter > Activated > Working > Other Plaintext). During conversations and tasks, it predicts which me...", "priority": 2, "bytes": 6857, "type": "guide"}
{"file": "overview-quick_start-overview.md", "path": "docs/processed/github-memos-docs/overview-quick_start-overview.md", "description": "Overview of ::note Tip<br> Before writing the first line of code, you can quickly experience the effect of ‚Äúmemory capability‚Äù through MemOS Playground.<br>.", "priority": 2, "bytes": 10310, "type": "guide"}
{"file": "usecase-financial_assistant.md", "path": "docs/processed/github-memos-docs/usecase-financial_assistant.md", "description": "In intelligent investment advisory products, users leave behind a large number of behavioral traces:.", "priority": 2, "bytes": 11655, "type": "documentation"}
{"file": "usecase-home_assistant.md", "path": "docs/processed/github-memos-docs/usecase-home_assistant.md", "description": "When developing a home life assistant product, developers often encounter a problem: once the dialogue context ends, user information is lost.", "priority": 2, "bytes": 11827, "type": "documentation"}
{"file": "usecase-writting_assistant.md", "path": "docs/processed/github-memos-docs/usecase-writting_assistant.md", "description": "In writing assistant products, users often hope that the assistant can remember their writing style and habits instead of starting from scratch each time.", "priority": 2, "bytes": 11721, "type": "documentation"}
